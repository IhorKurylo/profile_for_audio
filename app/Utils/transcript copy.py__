from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi
import nltk
import openai
from dotenv import load_dotenv
import os
import tiktoken
import time
import asyncio

load_dotenv()
tokenizer = tiktoken.get_encoding('cl100k_base')


def tiktoken_len(text):
    tokens = tokenizer.encode(
        text,
        disallowed_special=()
    )
    return len(tokens)


def extract_video_id(url):
    # Parse the URL
    parsed_url = urlparse(url)

    if parsed_url.netloc == 'youtu.be':
        # The video ID is the path itself for 'youtu.be' URLs
        return parsed_url.path[1:]
    if parsed_url.netloc in ('www.youtube.com', 'youtube.com'):
        if parsed_url.path == '/watch':
            # The video ID is in the 'v' query parameter for '/watch' paths
            return parse_qs(parsed_url.query)['v'][0]
        if parsed_url.path[:7] == '/embed/':
            # The video ID is the path itself for '/embed/' paths
            return parsed_url.path.split('/')[2]
        if parsed_url.path[:3] == '/v/':
            # The video ID is the path itself for '/v/' paths
            return parsed_url.path.split('/')[2]
    # Return None if no video ID could be extracted
    return None


def get_transcript_from_youtube(video_id: str):
    # nltk.download('punkt')
    # video_id = extract_video_id(url)
    # Get the transcript of the video
    transcript_list = YouTubeTranscriptApi.get_transcript(video_id)
    transcript = ' '.join([segment['text'] for segment in transcript_list])
    sentences = nltk.sent_tokenize(transcript)
    context = ""
    with open("./data/script.txt", "w") as txt_file:
        for sentence in sentences:
            txt_file.write(sentence + '.\n')
            context += sentence + '.\n'
    return context


async def get_response(subtext: str):
    result = ""
    start_time = time.time()
    instructor = f"""
        {subtext}
        
        ------------------------
        
        Please analyze above context carefully and then extract information about book, movie, article, podcast that are mentioned in the context in detail.
        Please check each sentence one by one so that you can extract all books, movies, articles, podcasts in the context above.        
    """

    print("tiktoken_len: ", tiktoken_len(instructor), '\n')
    try:
        response = await openai.ChatCompletion.acreate(
            model='gpt-4',
            max_tokens=500,
            messages=[
                {'role': 'system', 'content': instructor},
                {'role': 'user', 'content': f"""
                    Please provide me extracted data about books, movies, articles, podcasts mentioned above.
                    Output one by one as a list looks like below format.
                    
                    This is sample output
                    book:
                    "Stolen Focus" by Johann Hari
                    
                    Podcasts:
                    "Huberman Lab" by Dr. Andrew Huberman, this particular episode on Dr. Andrew Huberman's podcast is not specified, but he mentions having various guests on.
                    
                    Movie:
                    There's a mention of the TV show "Mad Men".
                    
                    ...
                """}
            ],
            # stream=True
        )
        result += response.choices[0].message.content + '\n'
        current_time = time.time()
        delta_time = current_time - start_time
        # print(response.choices[0].message.content + '\n')
        time.sleep(max(0, 60-delta_time))

        current_time = time.time()
        print("Elapsed time: ", current_time - start_time)

    except Exception as e:
        print(e)
    return result


async def extract_data(context: str):
    length = len(context)
    sub_len = 15000
    current = 0

    while current < length:
        tasks = []
        start = max(0, current - 50)
        end = min(current + sub_len, length - 1)
        current += sub_len
        subtext = context[start: end]
        tasks.append(get_response(subtext))
        if current < length:
            start = max(0, current - 50)
            end = min(current + sub_len, length - 1)
            current += sub_len
            subtext = context[start: end]
            tasks.append(get_response(subtext))
        await asyncio.gather(*tasks)


def complete_profile(context: str):
    # print("context: ", context, '\n')
    result = ""
    instructor = f"""
        All information about books, movies, articles, podcasts, etc mentioned in a particular talk is listed in the context given below.
        After carefully analyzing the below context, you need to categorize the information by topic, such as books, movies, articles, podcasts, etc.
        For that you have to check each sentence of below context one by one and extract all mentions about books, movies, articles, podcasts, etc.
        Then based on that information, complete the profile of each subject.
        Additionally, you must write a detailed profile for each topic based on the information given and your own knowledge about the topic.
        Don't say there is no mention about that topic.(In that case please describe with your own knowledge)
        Please ignore the sentences that says there is no mention about specific subject in the context.
        Don't miss any brief mentions of books, movies, articles, podcasts, etc from given context.
        In other word, all information about the books, movies, articles, podcasts, etc from given context below must be listed in your output.
        Avoid outputting too much context for each profile.
        
        --------------------------
        This is the given context you can refer to and it is containing information about books, movies, articles, podcasts, etc
        {context}
        
        Sample output like this.
        - Book
            "Stolen Focus":
            This book written by Johann Hari. The book delves into the modern world's crisis of attention, where our focus is constantly being pulled in different directions, leading to feelings of distraction and dissatisfaction. The author investigates how this state of constant distraction impacts our ability to think, work, and live fulfilling lives. He also provides insights into how we can reclaim our attention and focus. The book is based on extensive research and interviews with experts in various fields including technology, psychology, and neuroscience.
            
        - Movie
            "Mad Men":
            This is an American television series that aired from 2007 to 2015. The show was created by Matthew Weiner and produced by Lionsgate Television. The setting is a prestigious ad agency in 1960s New York City and it primarily focuses on the mysterious and talented ad executive Don Draper.
            The series is known for its historical authenticity, visual style, and character development. It explores themes such as the changing social mores of the United States during the 1960s, the tobacco industry, alcoholism, sexism, feminism, and the American Dream.
            "Mad Men" received critical acclaim and won many awards, including 16 Emmys and 5 Golden Globes. It is often cited as one of the greatest television shows of all time. The main cast includes Jon Hamm, Elisabeth Moss, Vincent Kartheiser, January Jones, Christina Hendricks, and John Slattery, among others.

        - Article
            ...


    """
    try:
        response = openai.ChatCompletion.create(
            model='gpt-4',
            max_tokens=1000,
            messages=[
                {'role': 'system', 'content': instructor},
                {'role': 'user', 'content': f"""
                    Please provide me profiles for each topics such as books, movies, articles, podcasts, etc.
                    All names and titles of books, movies, articles, podcasts, etc mentioned in the given context above should be listed in your output.
                """}
            ],
            # stream=True
        )
        print(response.choices[0].message.content + '\n')
        result = response.choices[0].message.content + '\n'
        return result

    except Exception as e:
        print(e)
